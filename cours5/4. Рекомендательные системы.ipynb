{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание по программированию: Рекомендательные системы\n",
    "\n",
    "## *Описание задачи*\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать **recall@k** и **precision@k**.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "### *Входные данные*\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - **id**-шниками просмотренных и **id**-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: **id** просмотренных товаров через , затем идёт ; после чего следуют **id** купленных товаров (если такие имеются), разделённые запятой. Например, **1,2,3,4**; или **1,2,3,4;5,6**.\n",
    "\n",
    "Гарантируется, что среди **id** купленных товаров все различные.\n",
    "\n",
    "***Важно:***\n",
    "\n",
    "- Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "- Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "- Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "- Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и **k** в **recall@k** / **precision@k**.\n",
    "\n",
    "## *Задание*\n",
    "\n",
    "1. На обучении постройте частоты появления **id** в просмотренных и в купленных (**id** может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "    - сортировка просмотренных **id** по популярности (частота появления в просмотренных),\n",
    "    - сортировка просмотренных **id** по покупаемости (частота появления в покупках).\n",
    "3. Для данных алгоритмов выпишите через пробел **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "### *Дополнительные вопросы*\n",
    "\n",
    "1. Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров **recall@k** меняется. Подумайте, как оценить минимальное и максимальное значение **recall@k** в зависимости от правила сортировки.\n",
    "2. Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('coursera_sessions_train.txt', sep=';', header=None, names = ['views', 'buys'])\n",
    "X_test = pd.read_csv('coursera_sessions_test.txt', sep=';', header=None, names = ['views', 'buys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def string_features_to_int(data, nan_place):\n",
    "    views, buys = list(), list()\n",
    "    for view, buy in zip(data['views'], data['buys']):\n",
    "        views.append([int(el) for el in view.split(',')])\n",
    "        if type(buy) == float:\n",
    "            buys.append(nan_place)\n",
    "        else:\n",
    "            buys.append([int(el) for el in buy.split(',')])\n",
    "    return views, buys\n",
    "views, buys = string_features_to_int(train, nan_place=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>buys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 6...</td>\n",
       "      <td>[67, 60, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[84, 85, 86, 87, 88, 89, 84, 90, 91, 92, 93, 86]</td>\n",
       "      <td>[86]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[138, 198, 199, 127]</td>\n",
       "      <td>[199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[303, 304, 305, 306, 307, 308, 309, 310, 311, ...</td>\n",
       "      <td>[303]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[352, 353, 352]</td>\n",
       "      <td>[352]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               views          buys\n",
       "0  [59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 6...  [67, 60, 63]\n",
       "1   [84, 85, 86, 87, 88, 89, 84, 90, 91, 92, 93, 86]          [86]\n",
       "2                               [138, 198, 199, 127]         [199]\n",
       "3  [303, 304, 305, 306, 307, 308, 309, 310, 311, ...         [303]\n",
       "4                                    [352, 353, 352]         [352]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame()\n",
    "views, X_buys = string_features_to_int(train, nan_place=np.nan)\n",
    "X_train['views'] = views\n",
    "X_train['buys']  = X_buys\n",
    "X_train.dropna(inplace=True)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train['views'] = views\n",
    "train['buys']  = buys\n",
    "\n",
    "views_cnt = Counter()\n",
    "buys_cnt  = Counter()\n",
    "for v_lst, b_lst in zip(train['views'], train['buys']):\n",
    "    for v_el in v_lst:\n",
    "        views_cnt[v_el] += 1\n",
    "    for b_el in b_lst:\n",
    "        buys_cnt[b_el] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>buys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[63, 68, 69, 70, 66, 61, 59, 61, 66, 68]</td>\n",
       "      <td>[66, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[158, 159, 160, 159, 161, 162]</td>\n",
       "      <td>[162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[200, 201, 202, 203, 204]</td>\n",
       "      <td>[201, 205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[371, 372, 371]</td>\n",
       "      <td>[371, 373]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[422]</td>\n",
       "      <td>[422]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      views        buys\n",
       "0  [63, 68, 69, 70, 66, 61, 59, 61, 66, 68]    [66, 63]\n",
       "1            [158, 159, 160, 159, 161, 162]       [162]\n",
       "2                 [200, 201, 202, 203, 204]  [201, 205]\n",
       "3                           [371, 372, 371]  [371, 373]\n",
       "4                                     [422]       [422]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_views, test_buys = string_features_to_int(X_test, nan_place=np.nan)\n",
    "X_test['views'] = test_views\n",
    "X_test['buys']  = test_buys\n",
    "X_test.dropna(inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(viewed, k, method='popular'):\n",
    "    unique_viewed = np.array(viewed)[np.sort(np.unique(viewed, return_index=True)[1])]    \n",
    "    k = min(len(viewed), k)    \n",
    "    ratings = []\n",
    "    \n",
    "    for item in unique_viewed:\n",
    "        if method == 'popular':\n",
    "            ratings.append(-views_cnt[item])\n",
    "        else:\n",
    "            ratings.append(-buys_cnt[item])\n",
    "    \n",
    "    sorted_items = np.argsort(ratings, kind='mergesort')\n",
    "    return list(unique_viewed[sorted_items])[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(predicted, buyed):\n",
    "    rb = [x for x in buyed if x in predicted]\n",
    "    return len(rb)/float(len(buyed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(predicted, buyed, k):\n",
    "    rb = [x for x in buyed if x in predicted]\n",
    "    return len(rb)/float(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.44263431659495955, 0.51219512195121952, 0.82469182471261182, 0.10243902439024391)\n",
      "(0.41733266203252556, 0.48130968622100956, 0.80003406635385776, 0.096261937244201901)\n",
      "(0.68844949242676512, 0.80376940133037689, 0.92630730242287906, 0.1607538802660754)\n",
      "(0.46062016666602978, 0.52769440654843114, 0.82018743374901959, 0.10553888130968621)\n"
     ]
    }
   ],
   "source": [
    "def get_stats(data, method='popular'):\n",
    "    ar1 = np.mean([recall   (predict(v, 1, method=method), b)    for v, b in zip(data['views'], data['buys'])])\n",
    "    ap1 = np.mean([precision(predict(v, 1, method=method), b, 1) for v, b in zip(data['views'], data['buys'])])\n",
    "    ar5 = np.mean([recall   (predict(v, 5, method=method), b)    for v, b in zip(data['views'], data['buys'])])\n",
    "    ap5 = np.mean([precision(predict(v, 1, method=method), b, 5) for v, b in zip(data['views'], data['buys'])])\n",
    "    return ar1, ap1, ar5, ap5\n",
    "\n",
    "train_popular = get_stats(X_train, 'popular')\n",
    "test_popular  = get_stats(X_test, 'popular')\n",
    "train_purch   = get_stats(X_train, 'purch')\n",
    "test_purch    = get_stats(X_test, 'purch')\n",
    "print train_popular\n",
    "print test_popular\n",
    "print train_purch\n",
    "print test_purch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer(assignment_N, answer):\n",
    "    with open(\"rank_{}.txt\".format(assignment_N), \"w\") as fout:\n",
    "        fout.write(' '.join([str(round(num, 2)) for num in answer]))\n",
    "\n",
    "write_answer(1, train_popular)\n",
    "write_answer(2, test_popular)\n",
    "write_answer(3, train_purch)\n",
    "write_answer(4, test_purch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
